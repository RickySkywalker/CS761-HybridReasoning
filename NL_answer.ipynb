{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3562aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-05 22:13:24 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "from utils import utils\n",
    "import re\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8488718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-05 22:13:38 config.py:542] This model supports multiple tasks: {'reward', 'generate', 'score', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-05 22:13:38 arg_utils.py:1135] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 05-05 22:13:38 config.py:1556] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "INFO 05-05 22:13:38 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='./data/models/Qwen3-8B', speculative_config=None, tokenizer='./data/models/Qwen3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=./data/models/Qwen3-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 05-05 22:13:40 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 05-05 22:13:40 model_runner.py:1110] Starting to load model ./data/models/Qwen3-8B...\n",
      "WARNING 05-05 22:13:40 utils.py:69] Qwen3ForCausalLM has no vLLM implementation, falling back to Transformers implementation. Some features may not be supported and performance may not be optimal.\n",
      "INFO 05-05 22:13:40 transformers.py:132] Using Transformers backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46d5cd3cc474579a4c2a0fe03ea8e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-05 22:13:43 model_runner.py:1115] Loading model weights took 15.2585 GB\n",
      "INFO 05-05 22:13:44 worker.py:267] Memory profiling takes 0.77 seconds\n",
      "INFO 05-05 22:13:44 worker.py:267] the current vLLM instance can use total_gpu_memory (47.41GiB) x gpu_memory_utilization (0.90) = 42.67GiB\n",
      "INFO 05-05 22:13:44 worker.py:267] model weights take 15.26GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 1.40GiB; the rest of the memory reserved for KV Cache is 25.95GiB.\n",
      "INFO 05-05 22:13:44 executor_base.py:110] # CUDA blocks: 11811, # CPU blocks: 1820\n",
      "INFO 05-05 22:13:44 executor_base.py:115] Maximum concurrency for 40960 tokens per request: 4.61x\n",
      "INFO 05-05 22:13:46 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:16<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-05 22:14:02 model_runner.py:1562] Graph capturing finished in 16 secs, took 0.71 GiB\n",
      "INFO 05-05 22:14:02 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 18.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"./data/models/Qwen3-8B\"\n",
    "model = LLM(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0119982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_500 = utils.read_from_json(\"./data/proved_Math-500.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4906d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Solve the following question Your answer should be in \\boxed\\{\\} format.\n",
      "\n",
      "Here is the question:\n",
      "Compute $58_9 - 18_9.$ Express your answer in base $9.$<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Solve the following question Your answer should be in \\\\boxed\\{\\} format.\n",
    "\n",
    "Here is the question:\n",
    "\"\"\" + math_500[0][\"problem\"] \n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True, \n",
    "    enable_thinking=True\n",
    ")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9dcc77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:55<00:00, 55.07s/it, est. speed input: 0.93 toks/s, output: 36.05 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to subtract two numbers in base 9: 58 base 9 minus 18 base 9. Hmm, let me think. First, I remember that when subtracting numbers in different bases, it's often easier to convert them to base 10, do the subtraction there, and then convert back to the original base. But maybe I can do it directly in base 9? Let me try both methods and see which is easier.\n",
      "\n",
      "Starting with converting to base 10. Let me recall how base conversion works. For base 9, each digit represents a power of 9. So, for the number 58_9, the rightmost digit is 8 * 9^0, and the next one is 5 * 9^1. Let me calculate that.\n",
      "\n",
      "First, 58_9:\n",
      "5 * 9^1 + 8 * 9^0 = 5*9 + 8*1 = 45 + 8 = 53 in base 10.\n",
      "\n",
      "Then, 18_9:\n",
      "1 * 9^1 + 8 * 9^0 = 1*9 + 8*1 = 9 + 8 = 17 in base 10.\n",
      "\n",
      "So subtracting them in base 10: 53 - 17 = 36. Now, I need to convert 36 back to base 9.\n",
      "\n",
      "To convert 36 to base 9, I need to find how many times 9^1 (which is 9) goes into 36, and then the remainder.\n",
      "\n",
      "Divide 36 by 9: 36 / 9 = 4 with a remainder of 0. So that would be 4*9^1 + 0*9^0, which is 40_9. Wait, so 40 base 9? Let me check that. 4*9 + 0 = 36. Yes, that's correct. So the answer is 40_9.\n",
      "\n",
      "But let me try doing the subtraction directly in base 9 to verify. Maybe I made a mistake in conversion?\n",
      "\n",
      "So, let's write down 58_9 minus 18_9. Let me align them vertically:\n",
      "\n",
      "   5 8\n",
      "-  1 8\n",
      "--------\n",
      "Starting from the rightmost digit: 8 - 8. That's straightforward, 0. Then the next digit: 5 - 1 = 4. So the result would be 40_9. Which matches the previous result. So that seems okay. Wait, so maybe that was easy? But let me check if there was a borrow needed. Wait, in the rightmost digit, 8 - 8 is 0, no problem. Then the next digit is 5 - 1 = 4. So no borrowing required. So the answer is 40_9. So both methods give me the same result. That seems good.\n",
      "\n",
      "But let me think again. Maybe I should check if there is a case where borrowing is needed. For example, if the top digit was smaller than the bottom digit. Let me try a different problem to test my understanding. Suppose I have 21_9 - 12_9. Converting to base 10: 2*9 +1=19, 1*9 +2=11. 19-11=8. Which is 8 in base 9, which is 8_9. Alternatively, subtracting directly:\n",
      "\n",
      "  2 1\n",
      "- 1 2\n",
      "------\n",
      "Starting from the right: 1 - 2. Oh, can't do that, so need to borrow. So borrow 1 from the 2 in the next digit. Since it's base 9, borrowing 1 from the 2 (which is in the 9's place) would add 9 to the units place. So the 2 becomes 1, and the 1 becomes 1 + 9 = 10. Then subtract 2 from 10: 10 - 2 = 8. Then the next digit is 1 - 1 = 0. So the result is 08_9, which is 8_9. Correct. So that works.\n",
      "\n",
      "But in our original problem, there was no need to borrow. So the answer is 40_9. But let me check once more.\n",
      "\n",
      "Alternatively, maybe I can think of the subtraction in base 9 as follows:\n",
      "\n",
      "58_9 - 18_9.\n",
      "\n",
      "First, subtract the units digits: 8 - 8 = 0. Then subtract the 9's digits: 5 - 1 = 4. So 40_9. Yep, that's straightforward.\n",
      "\n",
      "Alternatively, maybe I can check by adding 18_9 + 40_9 to see if I get 58_9. Let me try that.\n",
      "\n",
      "Adding 18_9 and 40_9:\n",
      "\n",
      "  1 8\n",
      "+ 4 0\n",
      "--------\n",
      "Starting from the right: 8 + 0 = 8. Then 1 + 4 = 5. So 58_9. Which is exactly the original number. Therefore, the subtraction is correct.\n",
      "\n",
      "So that seems to confirm that 58_9 - 18_9 = 40_9.\n",
      "\n",
      "But just to be thorough, let me check the base conversion again. 58_9 is 5*9 +8=45+8=53. 18_9 is 1*9 +8=17. 53-17=36. Now, converting 36 to base 9:\n",
      "\n",
      "Divide 36 by 9: 9*4=36, remainder 0. So 4*9 +0=36. So 40_9. Yep, that's correct.\n",
      "\n",
      "So both methods confirm that the answer is 40_9. Therefore, I think that is the correct answer.\n",
      "\n",
      "But just to make sure, let me think if there's another way to approach this. Maybe using base 9 subtraction rules?\n",
      "\n",
      "For example, in base 9, each digit is from 0 to 8. So when subtracting, if the top digit is smaller, you need to borrow. But in this case, since we don't have to borrow, it's straightforward. So 8-8=0, 5-1=4. So 40_9. Yep.\n",
      "\n",
      "Alternatively, if I wanted to do it in base 9 without converting, maybe I can think of it as:\n",
      "\n",
      "58_9 - 18_9 = (5*9 + 8) - (1*9 + 8) = (5*9 - 1*9) + (8 - 8) = 4*9 + 0 = 40_9. Exactly. So that's another way to see it.\n",
      "\n",
      "Therefore, all methods lead to the same answer. So I think that's solid. Therefore, the answer is 40 in base 9.\n",
      "\n",
      "**Final Answer**\n",
      "The result of $58_9 - 18_9$ expressed in base 9 is \\boxed{40_9}.\n",
      "</think>\n",
      "\n",
      "To solve the problem of subtracting two base-9 numbers, $58_9 - 18_9$, we can approach it either by converting the numbers to base 10 and then back to base 9, or by performing the subtraction directly in base 9. Both methods yield the same result, and we'll walk through both to ensure correctness.\n",
      "\n",
      "---\n",
      "\n",
      "### **Method 1: Convert to Base 10**\n",
      "\n",
      "We first convert both base-9 numbers to base 10:\n",
      "\n",
      "- $58_9 = 5 \\cdot 9^1 + 8 \\cdot 9^0 = 45 + 8 = 53_{10}$\n",
      "- $18_9 = 1 \\cdot 9^1 + 8 \\cdot 9^0 = 9 + 8 = 17_{10}$\n",
      "\n",
      "Now subtract in base 10:\n",
      "$$\n",
      "53_{10} - 17_{10} = 36_{10}\n",
      "$$\n",
      "\n",
      "Next, convert $36_{10}$ back to base 9:\n",
      "\n",
      "- $36 \\div 9 = 4$ remainder $0$\n",
      "- So, $36_{10} = 40_9$\n",
      "\n",
      "---\n",
      "\n",
      "### **Method 2: Direct Subtraction in Base 9**\n",
      "\n",
      "Align the numbers vertically:\n",
      "```\n",
      "  5 8\n",
      "- 1 8\n",
      "-------\n",
      "```\n",
      "\n",
      "Start from the rightmost digit:\n",
      "- $8 - 8 = 0$ (no borrow needed)\n",
      "- $5 - 1 = 4$\n",
      "\n",
      "So, the result is:\n",
      "$$\n",
      "40_9\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### **Verification by Addition**\n",
      "\n",
      "To confirm the result, we can add $18_9 + 40_9$ and check if it equals $58_9$:\n",
      "\n",
      "- $18_9 + 40_9 = 58_9$\n",
      "- This confirms the subtraction is correct.\n",
      "\n",
      "---\n",
      "\n",
      "### **Final Answer**\n",
      "\n",
      "$$\n",
      "\\boxed{40_9}\n",
      "$$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.95, max_tokens=8096)\n",
    "output = model.generate(text, sampling_params=sampling_params)\n",
    "output_text = output[0].outputs[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af84f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40_9\n"
     ]
    }
   ],
   "source": [
    "matches = re.findall(r'\\\\boxed\\{(.*?)\\}', output_text)\n",
    "\n",
    "if matches:\n",
    "    last_boxed = matches[-1]\n",
    "    print(last_boxed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a3705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
